{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyword Inclusion Score: 0.80\n",
      "Semantic Similarity: 0.84\n",
      "Impact-Driven Phrases: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'keyword_score': 0.8,\n",
       " 'semantic_similarity': np.float32(0.8382788),\n",
       " 'impact_phrases': 5}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyaspeller import YandexSpeller\n",
    "import textstat\n",
    "import PyPDF2  # For extracting text from PDFs\n",
    "import yake \n",
    "\n",
    "# Initialize tools\n",
    "grammar_tool = YandexSpeller()\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def extract_keywords(text, top_n=10):\n",
    "    \"\"\"Extract keywords using YAKE and spaCy.\"\"\"\n",
    "    # Use YAKE (Keyword Extraction)\n",
    "    kw_extractor = yake.KeywordExtractor(lan=\"en\", n=1, dedupLim=0.9, top=top_n)\n",
    "    yake_keywords = {kw for kw, _ in kw_extractor.extract_keywords(text)}\n",
    "\n",
    "    # Use spaCy for NLP processing\n",
    "    doc = nlp(text)\n",
    "    spacy_keywords = {token.lemma_ for token in doc if token.pos_ in [\"NOUN\", \"PROPN\", \"VERB\", \"ADJ\"]}\n",
    "\n",
    "    # Combine results & return top keywords\n",
    "    all_keywords = list(yake_keywords | spacy_keywords)\n",
    "    return sorted(all_keywords, key=lambda x: text.count(x), reverse=True)[:top_n]\n",
    "\n",
    "def keyword_inclusion_score(job_description, resume_text):\n",
    "    \"\"\"Calculates the percentage of job description keywords included in the resume.\"\"\"\n",
    "    keywords = extract_keywords(job_description)\n",
    "    included = [keyword for keyword in keywords if keyword in resume_text]\n",
    "    return len(included) / len(keywords)\n",
    "\n",
    "def semantic_similarity(original_text, edited_text):\n",
    "    \"\"\"Calculates semantic similarity between two texts.\"\"\"\n",
    "    embeddings = sentence_model.encode([original_text, edited_text])\n",
    "    return cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
    "\n",
    "def count_impact_phrases(text):\n",
    "    \"\"\"Counts impact-driven phrases in the text.\"\"\"\n",
    "    impact_words = [\"increased\", \"improved\", \"reduced\", \"achieved\", \"optimized\", \"enhanced\", \"utilized\"]\n",
    "    return sum(text.lower().count(word) for word in impact_words)\n",
    "\n",
    "def evaluate_resume(original_resume_path, optimized_resume_path, job_description):\n",
    "    \"\"\"Evaluates the optimized resume against the original resume and job description.\"\"\"\n",
    "    # Extract text\n",
    "    if original_resume_path.endswith(\".pdf\"):\n",
    "        original_text = extract_text_from_pdf(original_resume_path)\n",
    "    else:\n",
    "        original_text = extract_text_from_docx(original_resume_path)\n",
    "\n",
    "    if optimized_resume_path.endswith(\".pdf\"):\n",
    "        optimized_text = extract_text_from_pdf(optimized_resume_path)\n",
    "    else:\n",
    "        optimized_text = extract_text_from_docx(optimized_resume_path)\n",
    "\n",
    "    # Keyword inclusion\n",
    "    keyword_score = keyword_inclusion_score(job_description, optimized_text)\n",
    "\n",
    "    # Semantic similarity\n",
    "    similarity = semantic_similarity(original_text, optimized_text)\n",
    "\n",
    "    # Impact-driven phrases\n",
    "    impact_phrases = count_impact_phrases(optimized_text)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Keyword Inclusion Score: {keyword_score:.2f}\")\n",
    "    print(f\"Semantic Similarity: {similarity:.2f}\")\n",
    "    print(f\"Impact-Driven Phrases: {impact_phrases}\")\n",
    "\n",
    "    # Return metrics\n",
    "    return {\n",
    "        \"keyword_score\": keyword_score,\n",
    "        \"semantic_similarity\": similarity,\n",
    "        \"impact_phrases\": impact_phrases,\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "original_resume_path = \"/Users/aadi/Downloads/Deep Learning Applications - AIPI 540/Natural Language Processing/lllm-resume-optimizer/data/raw/Sample_Aaditey_Pillai_Resume.docx\"\n",
    "optimized_resume_path = \"/Users/aadi/Downloads/Deep Learning Applications - AIPI 540/Natural Language Processing/lllm-resume-optimizer/data/outputs/optimized_resume.docx\"\n",
    "\n",
    "job_description = \"\"\"\n",
    "About the job\n",
    "Lab Summary: AI Research Center (AIC) located in Mountain View, California focuses on research and development which directly impacts future Samsung products reaching hundreds of millions of users worldwide. We are focused on pushing the state-of-the-art and practice in natural language and knowledge intelligence.\n",
    "\n",
    "Position Summary: Samsung Research AI center, located in Mountain View, CA, is currently recruiting world-class students who can thrive in a fast-pace, cross team, results-driven environment, with focus on highly visible, challenging, and cross discipline projects. You will be part of an exciting project to build an adaptive, personalized, contextual and secure AI model and system to enable fast, accurate and safe interactions tailored to usersâ€™ needs on Samsung devices.\n",
    "\n",
    "Position Responsibilities\n",
    "\n",
    "Develop and implement novel deep learning/reinforcement learning algorithms for natural language processing (text, speech) in various applications\n",
    "Contribute to the research activities of our team\n",
    "Generate creative solutions (patents) and publish in top conferences (papers)\n",
    "\n",
    "Required Skills \n",
    "\n",
    "Teamwork and communication skills\n",
    "Current Ph.D. student in CS, EE, or related field\n",
    "Experience in one or more of the following areas:\n",
    "Strong background in machine learning (supervised learning, transfer learning, one-shot or few shot learning, unsupervised learning, semi-supervised learning, weakly supervised learning, meta-learning, outlier detection, etc.).\n",
    "Expertise in LLM including model architecture, training/finetuning techniques, retrieval augmented generation (RAG), reasoning and action planning, etc.\n",
    "Experience in conversational AI technologies: natural language processing (e.g., language models, semantic parsing, natural language generation etc.), dialogue (e.g., state tracking, policy learning), and representation learning (embedding, conceptualization, etc.).\n",
    "Experience in knowledge augmented AI technologies (e.g., language prompt, knowledge graph, neuro-symbolic learning).\n",
    "Experience in agentic AI is a plus.\n",
    "Experience in multimodal AI technologies for various multimodal applications.\n",
    "Experience in on-device AI technologies such as lightweight model architecture design.\n",
    "Proficiency in a neural network library (e.g., PyTorch, TensorFlow).\n",
    "Proven track record of research/publications on machine learning and artificial intelligence field (NeurIPS, ICML, ICLR, AAAI, IJCAI, CVPR, ACL, EMNLP, NAACL, TACL, etc.)\n",
    "\"\"\"\n",
    "\n",
    "evaluate_resume(original_resume_path, optimized_resume_path, job_description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
